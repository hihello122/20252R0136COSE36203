{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 39,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0784313725490196,
      "grad_norm": 2.039942502975464,
      "learning_rate": 0.0,
      "loss": 2.8395,
      "step": 1
    },
    {
      "epoch": 0.1568627450980392,
      "grad_norm": 1.7305039167404175,
      "learning_rate": 0.0001,
      "loss": 2.8384,
      "step": 2
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 1.2590254545211792,
      "learning_rate": 0.0002,
      "loss": 2.7078,
      "step": 3
    },
    {
      "epoch": 0.3137254901960784,
      "grad_norm": 1.2956773042678833,
      "learning_rate": 0.00019459459459459462,
      "loss": 2.6228,
      "step": 4
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 1.2127430438995361,
      "learning_rate": 0.0001891891891891892,
      "loss": 2.4043,
      "step": 5
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 1.2904349565505981,
      "learning_rate": 0.0001837837837837838,
      "loss": 2.1448,
      "step": 6
    },
    {
      "epoch": 0.5490196078431373,
      "grad_norm": 1.2702349424362183,
      "learning_rate": 0.00017837837837837839,
      "loss": 1.9951,
      "step": 7
    },
    {
      "epoch": 0.6274509803921569,
      "grad_norm": 1.4880601167678833,
      "learning_rate": 0.000172972972972973,
      "loss": 1.8313,
      "step": 8
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 1.5814436674118042,
      "learning_rate": 0.00016756756756756757,
      "loss": 1.6624,
      "step": 9
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 1.6715532541275024,
      "learning_rate": 0.00016216216216216218,
      "loss": 1.5312,
      "step": 10
    },
    {
      "epoch": 0.8627450980392157,
      "grad_norm": 1.7963123321533203,
      "learning_rate": 0.00015675675675675676,
      "loss": 1.3928,
      "step": 11
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 1.761346697807312,
      "learning_rate": 0.00015135135135135137,
      "loss": 1.2492,
      "step": 12
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.6368563175201416,
      "learning_rate": 0.00014594594594594595,
      "loss": 1.1341,
      "step": 13
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.0284123420715332,
      "eval_runtime": 3.91,
      "eval_samples_per_second": 5.627,
      "eval_steps_per_second": 0.767,
      "step": 13
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 1.8254450559616089,
      "learning_rate": 0.00014054054054054056,
      "loss": 1.1023,
      "step": 14
    },
    {
      "epoch": 1.156862745098039,
      "grad_norm": 1.6546099185943604,
      "learning_rate": 0.00013513513513513514,
      "loss": 0.922,
      "step": 15
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 1.5789247751235962,
      "learning_rate": 0.00012972972972972974,
      "loss": 0.8777,
      "step": 16
    },
    {
      "epoch": 1.3137254901960784,
      "grad_norm": 1.4590948820114136,
      "learning_rate": 0.00012432432432432433,
      "loss": 0.7205,
      "step": 17
    },
    {
      "epoch": 1.392156862745098,
      "grad_norm": 1.715437889099121,
      "learning_rate": 0.00011891891891891893,
      "loss": 0.6714,
      "step": 18
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 1.3171473741531372,
      "learning_rate": 0.00011351351351351351,
      "loss": 0.5933,
      "step": 19
    },
    {
      "epoch": 1.5490196078431373,
      "grad_norm": 1.7564374208450317,
      "learning_rate": 0.00010810810810810812,
      "loss": 0.5409,
      "step": 20
    },
    {
      "epoch": 1.6274509803921569,
      "grad_norm": 1.6869325637817383,
      "learning_rate": 0.0001027027027027027,
      "loss": 0.4748,
      "step": 21
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 1.9657177925109863,
      "learning_rate": 9.729729729729731e-05,
      "loss": 0.4788,
      "step": 22
    },
    {
      "epoch": 1.784313725490196,
      "grad_norm": 1.3388029336929321,
      "learning_rate": 9.18918918918919e-05,
      "loss": 0.3388,
      "step": 23
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 1.226231575012207,
      "learning_rate": 8.64864864864865e-05,
      "loss": 0.3782,
      "step": 24
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 1.2259858846664429,
      "learning_rate": 8.108108108108109e-05,
      "loss": 0.3739,
      "step": 25
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.4395416975021362,
      "learning_rate": 7.567567567567568e-05,
      "loss": 0.4086,
      "step": 26
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.25308316946029663,
      "eval_runtime": 2.2428,
      "eval_samples_per_second": 9.809,
      "eval_steps_per_second": 1.338,
      "step": 26
    },
    {
      "epoch": 2.0784313725490198,
      "grad_norm": 1.1249315738677979,
      "learning_rate": 7.027027027027028e-05,
      "loss": 0.3049,
      "step": 27
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 1.0332261323928833,
      "learning_rate": 6.486486486486487e-05,
      "loss": 0.1733,
      "step": 28
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 0.8899974226951599,
      "learning_rate": 5.9459459459459466e-05,
      "loss": 0.1901,
      "step": 29
    },
    {
      "epoch": 2.313725490196078,
      "grad_norm": 0.8736056685447693,
      "learning_rate": 5.405405405405406e-05,
      "loss": 0.1766,
      "step": 30
    },
    {
      "epoch": 2.392156862745098,
      "grad_norm": 0.8632893562316895,
      "learning_rate": 4.8648648648648654e-05,
      "loss": 0.0895,
      "step": 31
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 0.9509375691413879,
      "learning_rate": 4.324324324324325e-05,
      "loss": 0.1942,
      "step": 32
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.7286955714225769,
      "learning_rate": 3.783783783783784e-05,
      "loss": 0.126,
      "step": 33
    },
    {
      "epoch": 2.627450980392157,
      "grad_norm": 0.8511702418327332,
      "learning_rate": 3.2432432432432436e-05,
      "loss": 0.1374,
      "step": 34
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 1.0617223978042603,
      "learning_rate": 2.702702702702703e-05,
      "loss": 0.1767,
      "step": 35
    },
    {
      "epoch": 2.784313725490196,
      "grad_norm": 0.8540082573890686,
      "learning_rate": 2.1621621621621624e-05,
      "loss": 0.1456,
      "step": 36
    },
    {
      "epoch": 2.8627450980392157,
      "grad_norm": 0.8496930003166199,
      "learning_rate": 1.6216216216216218e-05,
      "loss": 0.0769,
      "step": 37
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.486995130777359,
      "learning_rate": 1.0810810810810812e-05,
      "loss": 0.0984,
      "step": 38
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5524368286132812,
      "learning_rate": 5.405405405405406e-06,
      "loss": 0.0994,
      "step": 39
    }
  ],
  "logging_steps": 1,
  "max_steps": 39,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7650527331926016.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
